{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Db2Sharp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This db2sharp application demonstrates the acceleration of the databroker interface for accessing and preprocessing large ptychographic datasets, for example: loading files directly within the script (106 s) vs loading files with the Spark parallel platform (22 s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# make graphics inline\n",
    "%matplotlib inline\n",
    "\n",
    "from SparkSharpReader import SparkSharpReader\n",
    "from SharpWriter import SharpWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Experiment-Specific Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sid = 27223\n",
    "fields = ['zpssx','zpssy']\n",
    "\n",
    "sharpReader = SparkSharpReader()\n",
    "# x_c, y_c, xn, yn, threshold\n",
    "sharpReader.init(64, 147, 128, 128, 2)\n",
    "\n",
    "sharpWriter = SharpWriter()\n",
    "# pixel size (um), distance (m), wavelength (nm), det_side \n",
    "sharpWriter.init(55, 0.64, 0.1331, 128) \n",
    "\n",
    "prbfile = '../../data/27223/recon_21678_t4_probe_ave_rp.npy'\n",
    "\n",
    "cxifile = '../../data/27223/hxn27223.cxi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting Metadata from Databroker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting fnames, points from db ...\n",
      "processing time:  0:00:18.517880 , fnames:  67200 , ic:  67200 , x:  67200 , y:  67200\n"
     ]
    }
   ],
   "source": [
    "print(\"getting fnames, points from db ...\");\n",
    "t1 = datetime.now();\n",
    "fnames, ic = sharpReader.get_merlin1_fnames(sid)\n",
    "xs, ys = sharpReader.get_points(sid, fields)\n",
    "t2 = datetime.now();\n",
    "print (\"processing time: \", (t2 - t1), \", fnames: \", len(fnames), \", ic: \", len(ic), \", x: \", len(xs), \", y: \", len(ys));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Files Directly within this Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files ...\n",
      "processing time:  0:01:46.392514 frames:  67200\n"
     ]
    }
   ],
   "source": [
    "print(\"loading files ...\");\n",
    "t1 = datetime.now();\n",
    "frames = sharpReader.load_files(sid, fnames, ic)\n",
    "t2 = datetime.now();\n",
    "print (\"processing time: \", (t2 - t1), \"frames: \", len(frames));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Files with Spark Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files ...\n",
      "processing time:  0:00:21.825956 frames:  67200\n"
     ]
    }
   ],
   "source": [
    "partitions = 20\n",
    "print(\"loading files ...\");\n",
    "t1 = datetime.now();\n",
    "frames = sharpReader.load_files_with_spark(sid, fnames, ic, partitions)\n",
    "t2 = datetime.now();\n",
    "print (\"processing time: \", (t2 - t1), \"frames: \", len(frames));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Data to the SHARP-NSLS2 Input File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write a cxi file ...\n",
      "processing time:  0:00:11.500009\n"
     ]
    }
   ],
   "source": [
    "print(\"write a cxi file ...\");\n",
    "t1 = datetime.now();\n",
    "sharpWriter.write(cxifile, prbfile, frames, xs, ys)\n",
    "t2 = datetime.now();\n",
    "print (\"processing time: \", (t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
